#!/usr/bin/env node

import fs from 'fs';
import path from 'path';
import chalk from 'chalk';

console.log(chalk.blue('üÜì Configurando alternativas gratuitas de IA...'));

const configPath = path.join(process.cwd(), 'mcp-config.env');
let configContent = '';

if (fs.existsSync(configPath)) {
  configContent = fs.readFileSync(configPath, 'utf8');
}

const freeAIConfig = `
# ====================================
# CONFIGURACI√ìN DE IA GRATUITA
# ====================================

# Ollama (Completamente gratuito - Local)
OLLAMA_ENABLED=true
OLLAMA_MODEL=llama2
OLLAMA_BASE_URL=http://localhost:11434

# Hugging Face (Gratuito con l√≠mites)
HUGGINGFACE_API_KEY=your-huggingface-key-here
HUGGINGFACE_MODEL=microsoft/DialoGPT-medium

# Groq (Gratuito con l√≠mites)
GROQ_API_KEY=your-groq-key-here
GROQ_MODEL=llama2-70b-4096

# Configuraci√≥n por defecto
DEFAULT_AI_PROVIDER=ollama
AI_FALLBACK_PROVIDER=huggingface
`;

if (!configContent.includes('OLLAMA_ENABLED')) {
  configContent += freeAIConfig;
  fs.writeFileSync(configPath, configContent);
  console.log(chalk.green('‚úÖ Configuraci√≥n de IA gratuita agregada'));
}

console.log(chalk.blue('\\nüìã OPCIONES GRATUITAS DISPONIBLES:'));
console.log(chalk.green('1. üê≥ Ollama - Completamente gratuito (Recomendado)'));
console.log(chalk.green('2. ü§ó Hugging Face - API gratuita'));
console.log(chalk.green('3. üöÄ Groq - Muy r√°pido, l√≠mites gratuitos'));

console.log(chalk.blue('\\nüéØ PARA INSTALAR OLLAMA:'));
console.log(chalk.yellow('curl -fsSL https://ollama.ai/install.sh | sh'));
console.log(chalk.yellow('ollama pull llama2'));

console.log(chalk.green('\\nüöÄ ¬°IA gratuita configurada!'));
